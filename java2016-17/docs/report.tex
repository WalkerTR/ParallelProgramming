\documentclass{article}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}



\hypersetup{
    colorlinks = true,
    linkcolor = blue,
    anchorcolor = blue
}

\graphicspath{{img/}}





\title{Parallelization of Sokoban in Java}

\author{Davide Dal Bianco \\ 2598719}

\begin{document}

\maketitle

\section{Introduction}
The Sokoban is a puzzle game, where according the rules the player can move his position inside the board until a particular condition is met. The given sequential algorithm explore the solutions space until a combination of moves bring the initial state to a final state. Since the solutions space is infinite, the game il solved by gradually increasing the maximum number of moves that the player can do. This means that the states are examined more the once during the resolution. In this report a solution to parallelize the sequential program will be provided, with the main aim of describing the techniques used and measuring the performance increasement.

\section{Parallel algorithm}
The provided sequential program uses a recursive function to compute all possible solutions which number of moves is below a given threshold. The board is then solved by increasing the threshold until at least one solution is found. \\
Two possible families of parallel algorithms to solve sokoban are:
\begin{itemize}
    \item A \textit{Master Worker} algorithm, where a master node creates jobs that are solved by an arbitrary number of workers.
    \item A \textit{Trasposition-Driven Scheduling} algorithm, where each node computes one move and distribute the resulting states among all the nodes according to a hash function.
\end{itemize}
However, according to the requirements, a Master Worker algorithm must be used, hence we will focus on this one only. \\
A typical Master Worker algorithm work as follows:
\begin{itemize}
    \item The master start creating the jobs and store them into a queue.
    \item The workers ask the master for job to process (work stealing), then return back the result (when needed) and/or broadcast some other information.
    \item The final solution is found by a worker or by the master using the results provided by the workers.
\end{itemize}
In the sokoban, the master can start to find the solution like in the sequential version. However, every time a board reaches a maximum number of moves, the resolution of that particular board is interrupted and the board is added to the jobs queue. In this way the master can partition the global space of the solutions, in order to partition the total work among the workers. Since each partition has a different amount of work to compute, it is important that the number of jobs is much higher than the number of workers, in order to minimize the load imbalance. On the other hand, a greater number of jobs introduce a greater communication overhead. It follows that a trade off between load imbalance and communication overhead must be found. \\
In order to reflect the provided sequential algorithm, the master solve the sokoban by gradually increasing the bound. Therefore there are two options:
\begin{itemize}
    \item The current bound is less than or equal MAXHOPS and in this case only the master solve the board.
    \item The current bound is greater than MAXHOPS and in this case the master computes only the first MAXHOPS moves and the boards and the workers complete the resolution.
\end{itemize}
On the other hand, the workers are accepting new jobs from the master and, when a job is solved, the result is returned to the master. Another possible solution could be storing the cumulative result in each worker and return it back when no more jobs are available. However, workers have to notify the master they are ready for accepting a new job and therefore the communication overhead is about the same. The first solution has been chosen for its simplicity (we can think the result is piggybacked with the notification). \\


\section{Implementation}
The parallel algorithm is implemented by means of two different classes which encapsulate the master and the worker behaviour. The program must work for each number of node (even one), therefore the master node must be also a worker node. Since we have two different classes that incapsulate the two roles, the master is executed in a different thread. \\
Ibis has a built in function that elects a single node from all the joined instances. This allows to pick up a random node that will work as master. Since the number of nodes is known before the execution, we can submit it to Ibis using the java argument \texttt{-Dibis.pool.size=\#}. In this way, Ibis allows to wait until all instances have joined the pool and allows to retrieve the pool size at runtime. \\
The main of the program works as follows:
\begin{itemize}
    \item Ibis elects the server.
    \item If the current node is the server, it reads the board from the file and execute the \texttt{Server} class in a new thread.
    \item The \texttt{Worker} class is executed in the main thread.
\end{itemize}
Though the Master and the Worker are executed in two different threads, the level of parallelism is nearly zero. In fact, during the first part of the resolution workers are idle and during the second part of the resolution the master is doing IO only. For speedup measurement we can therefore assume that Master and Worker do not run concurrently. \\
In the program three different channels are used:
\begin{itemize}
    \item \textbf{greets}, used as synchronization point and to send the receive ports used by workers to accept incoming jobs.
    \item \textbf{jobSubmit}, used by the master to send the jobs to the workers.
    \item \textbf{results}, used by the workers to send the result back to the master.
\end{itemize}
In order to avoid deadlock all receive ports are opened before send ports. On the other hand, send ports are closed before receive ports.


\subsection{Master} \label{sec:master}
At the beginning, the master wait for the greeting messages from all workers containing the port used to accept new jobs. Moreover, this works as synchronization point to ensure all workers are connected and ready. \\
After the startup phase, the master start solving the board by increasing the bound. Instead of the provided recursive function, an iterative one has been used. When the list of boards is created, there are two possibilities: the current bound is less equal than MAXHOPS and the master counts the number of solved boards, or the current bound is greater than MAXHOPS and the master send the jobs to the workers in three phases:
\begin{enumerate}
    \item It send a job to each worker.
    \item When a result is returned, it send a new job to the worker.
    \item When no more jobs are available, it waits for the remaining results.
\end{enumerate}
All the solutions returned by the workers are summed. If no solutions are found the bound is incremented and the procedure is repeated until at least one solution is found. \\
At the end, the master send a null value to each worker in order to terminate it.


\subsection{Worker}
The work cycle of the workers is really easy. After the initialization of the ports, a greeting message is sent to master containing the identifier of the port used to receive jobs. After that, it starts listening for a new job. When a new one arrives, it solved and the result is sent back to the master. This message is used also to notify the master that the worker has finished the job. Now iterate the process until a null value is received.


\section{Performance measurement}

\section{Improvements}

\subsection{Overlapping jobs creation and jobs forwarding}
In section \nameref{sec:master} we described how the master creates the jobs and only later submits them to the worker. During this time interval, workers are idle and therefore much computational power is wasted. Clearly, in order to maximize performance, we must reduce the idle time as much as possible. A good solution could be using a recursive function (like a deep-first search) to compute the jobs, in order to get the first jobs sooner and be able to send them to the workers. \\
However the job creation phase is less than 0.001\% of the execution time, hence this improvement wouldn't be noticeable. For this reason it has not been implemented.


\subsection{Overlapping consecutive bounds}
Like the previous improvements, when all jobs have been sent to the workers and the master is waiting for collecting the results, some workers are idle. Though no more jobs are available, it is likely that no solution are found and the master starts creating new jobs with a greater bound. Therefore, we can exploit the idle time and use it to start executing the jobs required by the next iteration. When all results are collected there are two possibilities: if a solution is found and the jobs created are just ignored (useless work), if a solution is not found we already started the following iteration and we can continue processing it. \\
Also this improvement has not been implemented since the results collection phase consist in a minimal part of the total time. Furthermore, a more complex mechanism for collecting the results is required.


\subsection{Reducing communication latencies}
During its work cycle, each worker receive a job from the master, execute it and return the result back to the master. The problem is between two iteration: when the worker send back the result it must wait for another job from the master. During this gap no work is done, thus this is a possible performance loss. In order to reduce communication latencies, the next job should be sent before the worker complete the current one. In other words, at least one job should be always pending in the receive channel. This is relatively easy to implement, since it can be done by sending two messages to each worker in the first of the three sending phase. However, an unexpected performance loss has been detected. This happened due to the really small communication latencies in the cluster and the overhead caused by the higher load imbalance.


\end{document}